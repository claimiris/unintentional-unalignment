{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn0G131pK1pl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Unintentional_Unalignment/unintentional-unalignment') #cloned repo to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdCvdn92PgQF"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M86yO3ANPlRF"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token='token')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BdAzR3zPnNv"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.login(key=\"token\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDGKpDGPPZCx"
      },
      "outputs": [],
      "source": [
        "!wget -O \"data_files/persona/ends-justify-means.jsonl\" \"https://huggingface.co/datasets/Anthropic/model-written-evals/resolve/main/persona/ends-justify-means.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTLqtjQETgTn"
      },
      "source": [
        "Experiment 1: Section 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Ou5ucdKqRp"
      },
      "source": [
        "SFT Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoRIilMNTVRY"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_sft_olmo1b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeWk9cH5TWag"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_sft_gemma2b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ibBjIQnKrze"
      },
      "source": [
        "Experiments on models after SFT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6ZQ5natTWsE"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_post_sft_olmo1b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JT5AqY9ZzHe"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_post_sft_gemma2b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rccITET_LM-M"
      },
      "source": [
        "Experiments on base models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaL7fssdZzB8"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_base_olmo1b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e68cAf4eZ4NR"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_base_gemma2b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S-xcbS5LQAp"
      },
      "source": [
        "Experiments on models with IPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D6D4oXmaE1u"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_post_sft_ipo_olmo1b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Um_dj30SaEyK"
      },
      "outputs": [],
      "source": [
        "!python persona_single_example_experiment_plan_runner.py --plan_config_path persona_experiments/experiments_plans/persona_post_sft_ipo_gemma2b_experiments_plan.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH8pMo_ETiye"
      },
      "source": [
        "Experiment 2: Section 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmfY6NSme22x"
      },
      "source": [
        "DPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK9qecvtbLXv"
      },
      "source": [
        "OLMo-1b model + Alpaca Farm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-zuX6EAf1xu"
      },
      "source": [
        "Modify compute_preference_similarity_per_example.py to include url directly:\n",
        "\n",
        "if dataset_name == \"tatsu-lab/alpaca_farm\":\n",
        "        url = \"https://huggingface.co/datasets/tatsu-lab/alpaca_farm/resolve/main/alpaca_human_preference.json\"\n",
        "        return datasets.load_dataset(\"json\", data_files=url, split=\"train\", cache_dir=cache_dir)\n",
        "\n",
        "Include float explicitely:\n",
        "\n",
        "torch.quantile(ches_scores.float(), q=0.25)\n",
        "\n",
        "torch.quantile(ln_ches_scores.float(), q=0.25)\n",
        "\n",
        "torch.quantile(last_hidden_embedding_inner_prods.float(), q=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WymFJIq5TkmP"
      },
      "outputs": [],
      "source": [
        "!python compute_preference_similarity_per_example.py \\\n",
        "  --model allenai/OLMo-1B-hf \\\n",
        "  --dataset tatsu-lab/alpaca_farm \\\n",
        "  --output_dir outputs/pref_similarity \\\n",
        "  --num_train_samples 5000 \\\n",
        "  --gpu_id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a4zOvUMbD-e"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LVmHXjpaWwg"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_runner.py \\\n",
        "  --run_name alpaca_olmo_ches_0.0 \\\n",
        "  --model allenai/OLMo-1B-hf \\\n",
        "  --preference_similarity_path \"outputs/pref_similarity/OLMo-1B-hf_alpaca_farm/results_samples.pt\" \\\n",
        "  --use_samples_with_preference_similarity_quantile 0.0 \\\n",
        "  --pref_similarity_measure ches_scores \\\n",
        "  --preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "  --model_parallel_without_accelerate \\\n",
        "  --seed -1 \\\n",
        "  --wandb_project alpaca_dpo \\\n",
        "  --preference_num_samples 512 \\\n",
        "  --batch_size_per_gpu_proc 4 \\\n",
        "  --gradient_accumulation_steps 8 \\\n",
        "  --kl_coeff 0.1 \\\n",
        "  --learning_rate 1e-7 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --eval_every_epochs 1 \\\n",
        "  --save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itEzdX91bbw_"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKhJb8VGbUJt"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_runner.py \\\n",
        "  --run_name alpaca_olmo_edit_0.0 \\\n",
        "  --model allenai/OLMo-1B-hf \\\n",
        "  --preference_similarity_path \"outputs/pref_similarity/OLMo-1B-hf_alpaca_farm/results_samples.pt\" \\\n",
        "  --use_samples_with_preference_similarity_quantile 0.0 \\\n",
        "  --pref_similarity_measure minus_normalized_edit_distances \\\n",
        "  --preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "  --model_parallel_without_accelerate \\\n",
        "  --seed -1 \\\n",
        "  --wandb_project alpaca_dpo \\\n",
        "  --preference_num_samples 512 \\\n",
        "  --batch_size_per_gpu_proc 4 \\\n",
        "  --gradient_accumulation_steps 8 \\\n",
        "  --kl_coeff 0.1 \\\n",
        "  --learning_rate 1e-7 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --eval_every_epochs 1 \\\n",
        "  --save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_atXzVhlba1b"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZAKHzKbbVU5"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_runner.py \\\n",
        "  --run_name alpaca_olmo_hemm_0.0 \\\n",
        "  --model allenai/OLMo-1B-hf \\\n",
        "  --preference_similarity_path \"outputs/pref_similarity/OLMo-1B-hf_alpaca_farm/results_samples.pt\" \\\n",
        "  --use_samples_with_preference_similarity_quantile 0.0 \\\n",
        "  --pref_similarity_measure last_hidden_embedding_inner_prods \\\n",
        "  --preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "  --model_parallel_without_accelerate \\\n",
        "  --seed -1 \\\n",
        "  --wandb_project alpaca_dpo \\\n",
        "  --preference_num_samples 512 \\\n",
        "  --batch_size_per_gpu_proc 4 \\\n",
        "  --gradient_accumulation_steps 8 \\\n",
        "  --kl_coeff 0.1 \\\n",
        "  --learning_rate 1e-7 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --eval_every_epochs 1 \\\n",
        "  --save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCWK_riwcAtn"
      },
      "source": [
        "Gemma-2-9b + AlpacaFarm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SxicmsmdbVa"
      },
      "outputs": [],
      "source": [
        "!python compute_preference_similarity_per_example.py \\\n",
        "--model google/gemma-2-9b \\\n",
        "--dataset tatsu-lab/alpaca_farm \\\n",
        "--output_dir outputs/pref_similarity \\\n",
        "--num_train_samples 5000 \\\n",
        "--gpu_id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0OGXUEAdknz"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjFAcuchdVlT"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_fix.py \\\n",
        "--run_name alpaca_gemma9b_ches_0.00\\\n",
        "--model google/gemma-2-9b \\\n",
        "--preference_similarity_path outputs/pref_similarity/gemma-2-9b_alpaca_farm/results_samples.pt\\\n",
        "--use_samples_with_preference_similarity_quantile 0.00 \\\n",
        "--pref_similarity_measure ches_scores \\\n",
        "--preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--seed -1 \\\n",
        "--wandb_project alpaca_dpo \\\n",
        "--preference_num_samples 1024 \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--kl_coeff 0.1 \\\n",
        "--learning_rate 1e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8rSKhIydm4X"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuKtBfwkdnXu"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_fix.py \\\n",
        "--run_name alpaca_gemma9b_edit_0.00\\\n",
        "--model google/gemma-2-9b \\\n",
        "--preference_similarity_path outputs/pref_similarity/gemma-2-9b_alpaca_farm/results_samples.pt\\\n",
        "--use_samples_with_preference_similarity_quantile 0.00 \\\n",
        "--pref_similarity_measure minus_normalized_edit_distances \\\n",
        "--preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--seed -1 \\\n",
        "--wandb_project alpaca_dpo \\\n",
        "--preference_num_samples 1024 \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--kl_coeff 0.1 \\\n",
        "--learning_rate 1e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmD1lAHfdm7Q"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7UPTXaMdtrA"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_fix.py \\\n",
        "--run_name alpaca_gemma9b_hemm_0.00\\\n",
        "--model google/gemma-2-9b \\\n",
        "--preference_similarity_path outputs/pref_similarity/gemma-2-9b_alpaca_farm/results_samples.pt\\\n",
        "--use_samples_with_preference_similarity_quantile 0.00 \\\n",
        "--pref_similarity_measure last_hidden_embedding_inner_prods \\\n",
        "--preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--seed -1 \\\n",
        "--wandb_project alpaca_dpo \\\n",
        "--preference_num_samples 1024 \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--kl_coeff 0.1 \\\n",
        "--learning_rate 1e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoZnz0PAcEs2"
      },
      "source": [
        "(Also ran for Gemma-2b + Ultrafeedback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj8gdOXFcYq9"
      },
      "outputs": [],
      "source": [
        "python compute_preference_similarity_per_example.py \\\n",
        "--model google/gemma-2-9b \\\n",
        "--dataset HuggingFaceH4/ultrafeedback_binarized \\\n",
        "--output_dir outputs/pref_similarity \\\n",
        "--num_train_samples 5000 \\\n",
        "--train_samples_random_seed 548 \\\n",
        "--gpu_id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHpJyaUsedHJ"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_fix.py \\\n",
        "--run_name alpaca_gemma9b_ches_0.00\\\n",
        "--model google/gemma-2-9b \\\n",
        "--preference_similarity_path outputs/pref_similarity/gemma-2-9b_alpaca_farm/results_samples.pt\\\n",
        "--use_samples_with_preference_similarity_quantile 0.00 \\\n",
        "--pref_similarity_measure ches_scores \\\n",
        "--preference_dataset_path HuggingFaceH4/ultrafeedback_binarized \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--seed -1 \\\n",
        "--wandb_project ultrafeedback_dpo \\\n",
        "--preference_num_samples 512 \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--kl_coeff 0.1 \\\n",
        "--learning_rate 1e-7 \\\n",
        "--num_train_epochs 1 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLAWRxdaebeg"
      },
      "source": [
        "IPO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URmVJgk1e58F"
      },
      "source": [
        "OLMo-1b + AlpacaFarm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj29G5LyfK3i"
      },
      "source": [
        "Variations of the following code for quantile 0.0, 0.25, 0.5, 0.75, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGy7DZhBfGf2"
      },
      "outputs": [],
      "source": [
        "!python similarity_measures_experiment_runner.py \\\n",
        "  --run_name alpaca_olmo_ches_0.0 \\\n",
        "  --model allenai/OLMo-1B-hf \\\n",
        "  --preference_similarity_path \"outputs/pref_similarity/OLMo-1B-hf_alpaca_farm/results_samples.pt\" \\\n",
        "  --use_samples_with_preference_similarity_quantile 0.0 \\\n",
        "  --pref_similarity_measure ches_scores \\\n",
        "  --preference_dataset_path tatsu-lab/alpaca_farm \\\n",
        "  --objective ipo \\\n",
        "  --model_parallel_without_accelerate \\\n",
        "  --seed -1 \\\n",
        "  --wandb_project alpaca_ipo \\\n",
        "  --preference_num_samples 512 \\\n",
        "  --batch_size_per_gpu_proc 4 \\\n",
        "  --gradient_accumulation_steps 8 \\\n",
        "  --kl_coeff 0.1 \\\n",
        "  --learning_rate 1e-7 \\\n",
        "  --num_train_epochs 1 \\\n",
        "  --eval_every_epochs 1 \\\n",
        "  --save_every_epochs -1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQhwBUomb7Zo"
      },
      "source": [
        "Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeE257nH5yU7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_DZJeRJb8bP"
      },
      "outputs": [],
      "source": [
        "root_path = Path(\"./outputs/alpaca_dpo/gemma\") #run for other similar paths\n",
        "\n",
        "def convert_all_jsonl_in_folder(root_dir):\n",
        "    if not root_dir.exists():\n",
        "        print(f\"Error: Directory '{root_dir}' not found. Please check the path.\")\n",
        "        return\n",
        "\n",
        "    for experiment_folder in root_dir.iterdir():\n",
        "\n",
        "        if experiment_folder.is_dir():\n",
        "            print(f\"Processing folder: {experiment_folder.name}\")\n",
        "\n",
        "            jsonl_files = list(experiment_folder.glob(\"*.jsonl\"))\n",
        "\n",
        "            if not jsonl_files:\n",
        "                print(\"  -> No .jsonl files found.\")\n",
        "                continue\n",
        "\n",
        "            for jsonl_file in jsonl_files:\n",
        "                try:\n",
        "                    df = pd.read_json(jsonl_file, lines=True)\n",
        "\n",
        "                    txt_file_path = jsonl_file.with_suffix('.txt')\n",
        "\n",
        "                    df.to_string(txt_file_path, index=False)\n",
        "\n",
        "                    print(f\"  -> Converted: {jsonl_file.name}  ==>  {txt_file_path.name}\")\n",
        "\n",
        "                except ValueError:\n",
        "                    print(f\"  -> Skipping {jsonl_file.name} (File might be empty or corrupt)\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  -> Error converting {jsonl_file.name}: {e}\")\n",
        "\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "convert_all_jsonl_in_folder(root_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5H3EaWQmpXX"
      },
      "outputs": [],
      "source": [
        "experiments_config = [\n",
        "    {\"path\": \"./outputs/alpaca_dpo/olmo\", \"label\": \"OLMo-1b (DPO, AlpacaFarm)\"},\n",
        "    {\"path\": \"./outputs/alpaca_ipo/olmo\", \"label\": \"OLMo-1b (IPO, AlpacaFarm)\"},\n",
        "]\n",
        "\n",
        "def parse_experiments(root_dir_str, method_label):\n",
        "    data = []\n",
        "    root_dir = Path(root_dir_str)\n",
        "\n",
        "    if not root_dir.exists():\n",
        "        print(f\"Warning: Directory '{root_dir}' not found. Skipping.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    folder_pattern = re.compile(r\"^(?P<dataset>[a-z0-9]+)_(?P<model>[a-z0-9]+)_(?P<type>[a-z]+)_.*quantile_(?P<quantile>[\\d\\.]+)_\")\n",
        "\n",
        "    print(f\"Scanning {method_label} at {root_dir}...\")\n",
        "\n",
        "    for folder in root_dir.iterdir():\n",
        "        if not folder.is_dir():\n",
        "            continue\n",
        "\n",
        "        match = folder_pattern.search(folder.name)\n",
        "        if not match:\n",
        "            continue\n",
        "\n",
        "        sim_type = match.group(\"type\")\n",
        "        quantile = float(match.group(\"quantile\")) * 100\n",
        "\n",
        "        txt_path = folder / \"eval_metrics.txt\"\n",
        "        jsonl_path = folder / \"eval_metrics.jsonl\"\n",
        "\n",
        "        df = None\n",
        "        try:\n",
        "            if txt_path.exists():\n",
        "                df = pd.read_csv(txt_path, sep=r'\\s+')\n",
        "            elif jsonl_path.exists():\n",
        "                df = pd.read_json(jsonl_path, lines=True)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "        if df is None or df.empty:\n",
        "            continue\n",
        "\n",
        "        change_cols = [c for c in df.columns if \"preferred_logprobs_change_mean\" in c]\n",
        "        logprob_cols = [c for c in df.columns if \"preferred_logprobs_mean\" in c and \"reference\" not in c and \"change\" not in c]\n",
        "\n",
        "        final_val = 0.0\n",
        "\n",
        "        if change_cols:\n",
        "            col_name = change_cols[0]\n",
        "            final_val = df[col_name].iloc[-1]\n",
        "        elif logprob_cols:\n",
        "            col_name = logprob_cols[0]\n",
        "            final_val = df[col_name].iloc[-1] - df[col_name].iloc[0]\n",
        "\n",
        "        data.append({\n",
        "            \"Method\": method_label,\n",
        "            \"Similarity Type\": sim_type,\n",
        "            \"Preference Similarity (Percentile)\": quantile,\n",
        "            \"Change in Preferred Log Probability\": final_val\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "all_dataframes = []\n",
        "\n",
        "for exp in experiments_config:\n",
        "    df = parse_experiments(exp[\"path\"], exp[\"label\"])\n",
        "    all_dataframes.append(df)\n",
        "\n",
        "if all_dataframes:\n",
        "    df_results = pd.concat(all_dataframes, ignore_index=True)\n",
        "else:\n",
        "    df_results = pd.DataFrame()\n",
        "\n",
        "if not df_results.empty:\n",
        "    print(f\"\\nSuccessfully extracted {len(df_results)} data points.\")\n",
        "\n",
        "    name_map = {\n",
        "        \"ches\": \"CHES Score\",\n",
        "        \"edit\": \"Edit Distance Similarity\",\n",
        "        \"hidden\": \"Hidden Embedding Similarity\",\n",
        "        \"hemm\": \"Hidden Embedding Similarity\"\n",
        "    }\n",
        "    df_results[\"Similarity Type\"] = df_results[\"Similarity Type\"].map(name_map).fillna(df_results[\"Similarity Type\"])\n",
        "\n",
        "    unique_methods = df_results[\"Method\"].unique()\n",
        "\n",
        "    for method in unique_methods:\n",
        "        subset_data = df_results[df_results[\"Method\"] == method]\n",
        "\n",
        "        plt.figure(figsize=(6, 5))\n",
        "\n",
        "        sns.lineplot(\n",
        "            data=subset_data,\n",
        "            x=\"Preference Similarity (Percentile)\",\n",
        "            y=\"Change in Preferred Log Probability\",\n",
        "            hue=\"Similarity Type\",\n",
        "            style=\"Similarity Type\",\n",
        "            markers=True,\n",
        "            dashes=False,\n",
        "            linewidth=2.5,\n",
        "            palette=[\"#2ca02c\", \"#d62728\", \"#1f77b4\"]\n",
        "        )\n",
        "\n",
        "        plt.title(method) #sets the title to the method name\n",
        "        plt.axhspan(-3, 0, color='red', alpha=0.1, label='Likelihood Displacement')\n",
        "        plt.axhline(0, color='black', linewidth=0.8, linestyle='--')\n",
        "        plt.yticks([-5, 0, 5, 10, 15])\n",
        "        plt.xticks([0, 25, 50, 75, 100])\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "        clean_filename = re.sub(r'[^a-zA-Z0-9]', '_', method) + \".png\"\n",
        "\n",
        "        plt.savefig(clean_filename, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Saved graph to: {clean_filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"No data found! Please check your paths in experiments_config.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xz8DhE1Tk13"
      },
      "source": [
        "Experiment 3: Section 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MhfMPn1qNM8"
      },
      "source": [
        "Gemma-2b-it + SORRY-Bench"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuzXnLHPPRSk"
      },
      "source": [
        "Modify the sorrybench_create_preferences_dataset.py file\n",
        "\n",
        "with gemma-2b,we get:\n",
        "  \n",
        "ValueError: Cannot use chat template functions because tokenizer.chat_template is not set and no template argument was passed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oSpEJpcqN_N"
      },
      "outputs": [],
      "source": [
        "!python sorrybench_create_preferences_dataset.py \\\n",
        "--model google/gemma-2b-it \\\n",
        "--use_rm \\\n",
        "--gpu_id 0 \\\n",
        "--random_seed 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMxLugdYqXmZ"
      },
      "outputs": [],
      "source": [
        "!python sorrybench_evaluate_refusal_rate.py \\\n",
        "--models google/gemma-2b-it \\\n",
        "--dataset_path data_files/sorrybench/gemma-2b-it_seed_128_temp_1_topp_1_test_0-15_use_pairrm_2025-12-18_00-20-23 \\\n",
        "--output_dir outputs/sorrybench_refusal_rates \\\n",
        "--gpu_id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcg1RZK0qcnH"
      },
      "outputs": [],
      "source": [
        "!python compute_preference_similarity_per_example.py \\\n",
        "--model google/gemma-2b-it \\\n",
        "--dataset data_files/sorrybench/gemma-2b-it_seed_128_temp_1_topp_1_test_0-15_use_pairrm_2025-12-18_00-20-23/train.jsonl \\\n",
        "--output_dir outputs/pref_similarity \\\n",
        "--custom_dataset_display_name sorrybench \\\n",
        "--max_input_length -1 \\\n",
        "--gpu_id 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIDylYAfqhp2"
      },
      "outputs": [],
      "source": [
        "!python sorrybench_experiment_runner.py \\\n",
        "--run_name gemma_dpo_sft \\\n",
        "--model google/gemma-2b-it \\\n",
        "--dataset_path data_files/sorrybench/gemma-2b-it_seed_128_temp_1_topp_1_test_0-15_use_pairrm_2025-12-18_00-20-23 \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--wandb_project sorrybench_dpo \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1 \\\n",
        "--refusal_eval_batch_size 16 \\\n",
        "--sft_coeff 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAUdOvhlqj19"
      },
      "outputs": [],
      "source": [
        "!python sorrybench_experiment_runner.py \\\n",
        "--run_name gemma_dpo_filtered_ches \\\n",
        "--model google/gemma-2b \\\n",
        "--dataset_path data_files/sorrybench/gemma-2b-it_seed_128_temp_1_topp_1_test_0-15_use_pairrm_2025-12-18_00-20-23 \\\n",
        "--preference_similarity_path outputs/pref_similarity/gemma-2b-it_sorrybench/results_samples.pt \\\n",
        "--pref_similarity_measure ln_ches_scores \\\n",
        "--preference_num_samples 19 \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--wandb_project sorrybench_dpo \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--learning_rate 5e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1 \\\n",
        "--refusal_eval_batch_size 16 \\\n",
        "--sft_coeff 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEaOc9McqmWo"
      },
      "outputs": [],
      "source": [
        "!python sorrybench_experiment_runner.py \\\n",
        "--run_name gemma_dpo_gold \\\n",
        "--model google/gemma-2b-it \\\n",
        "--dataset_path data_files/sorrybench/gemma-2b-it_seed_128_temp_1_topp_1_test_0-15_use_pairrm_2025-12-18_00-20-23 \\\n",
        "--use_gold_preferences \\\n",
        "--model_parallel_without_accelerate \\\n",
        "--wandb_project sorrybench_dpo \\\n",
        "--batch_size_per_gpu_proc 4 \\\n",
        "--gradient_accumulation_steps 8 \\\n",
        "--learning_rate 1e-6 \\\n",
        "--num_train_epochs 3 \\\n",
        "--eval_every_epochs 1 \\\n",
        "--save_every_epochs -1 \\\n",
        "--refusal_eval_batch_size 16 \\\n",
        "--sft_coeff 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mlPflVnr0yf"
      },
      "source": [
        "Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnFMGMTpr2Kq"
      },
      "outputs": [],
      "source": [
        "outputs_dir = Path(\"./outputs/sorrybench_dpo\")\n",
        "model_name = \"Gemma-2B-IT\"\n",
        "\n",
        "base_model_train_eval = 0.8081081081081081\n",
        "\n",
        "colors = {\n",
        "    \"Initial\": \"#666666\",\n",
        "    \"DPO\": \"#D9534F\",\n",
        "    \"DPO + SFT\": \"#5CB85C\",\n",
        "    \"DPO (gold)\": \"#F0AD4E\",\n",
        "    \"DPO (filtered)\": \"#5BC0DE\"\n",
        "}\n",
        "\n",
        "mapping = [\n",
        "    (\"gold\", \"DPO (gold)\"),\n",
        "    (\"sft\", \"DPO + SFT\"),\n",
        "    (\"filter\", \"DPO (filtered)\"),\n",
        "    (\"dpo\", \"DPO\"),\n",
        "]\n",
        "\n",
        "def load_refusal_data(root_dir):\n",
        "    data = []\n",
        "\n",
        "    data.append({\n",
        "        \"Method\": \"Initial\",\n",
        "        \"Refusal Rate (%)\": base_model_train_eval * 100,\n",
        "        \"Run\": \"Base\"\n",
        "    })\n",
        "\n",
        "    files = list(root_dir.glob(\"**/*_refusal_eval.json\")) + list(root_dir.glob(\"**/*_refusal_eval.txt\"))\n",
        "\n",
        "    for file_path in files:\n",
        "        folder_name = file_path.parent.name.lower()\n",
        "        method_label = \"Unknown\"\n",
        "\n",
        "        for keyword, label in mapping:\n",
        "            if keyword in folder_name:\n",
        "                method_label = label\n",
        "                break\n",
        "\n",
        "        refusal_val = None\n",
        "\n",
        "        with open(file_path, 'r') as f:\n",
        "            content = json.load(f)\n",
        "            refusal_val = content.get(\"train_refusal_rate\")\n",
        "\n",
        "        if refusal_val is not None:\n",
        "            rate_percent = float(refusal_val) * 100\n",
        "            data.append({\n",
        "                \"Method\": method_label,\n",
        "                \"Refusal Rate (%)\": rate_percent,\n",
        "                \"Run\": file_path.parent.name\n",
        "            })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def aggregate_stats(df):\n",
        "    stats = df.groupby(\"Method\")[\"Refusal Rate (%)\"].agg(['mean', 'min', 'max']).reset_index()\n",
        "\n",
        "    stats['err_lower'] = stats['mean'] - stats['min']\n",
        "    stats['err_upper'] = stats['max'] - stats['mean']\n",
        "\n",
        "    custom_order = [\"Initial\", \"DPO\", \"DPO + SFT\", \"DPO (gold)\", \"DPO (filtered)\"]\n",
        "    stats['Method'] = pd.Categorical(stats['Method'], categories=custom_order, ordered=True)\n",
        "    stats = stats.sort_values('Method').dropna()\n",
        "\n",
        "    return stats\n",
        "\n",
        "def plot_figure_3_style(stats_df):\n",
        "    plt.figure(figsize=(9, 6))\n",
        "\n",
        "    x_pos = np.arange(len(stats_df))\n",
        "    methods = stats_df[\"Method\"].tolist()\n",
        "    means = stats_df[\"mean\"].tolist()\n",
        "\n",
        "    yerr = [stats_df['err_lower'].tolist(), stats_df['err_upper'].tolist()]\n",
        "\n",
        "    bar_colors = [colors.get(m, \"#333333\") for m in methods]\n",
        "\n",
        "    bars = plt.bar(x_pos, means,\n",
        "                   yerr=yerr,\n",
        "                   capsize=6,\n",
        "                   color=bar_colors,\n",
        "                   edgecolor='white',\n",
        "                   width=0.7,)\n",
        "\n",
        "    max_y_limit = 0\n",
        "    for rect, mean_val, method in zip(bars, means, methods):\n",
        "        height = rect.get_height()\n",
        "\n",
        "        row = stats_df[stats_df['Method'] == method].iloc[0]\n",
        "        top_point = row['max']\n",
        "\n",
        "        plt.text(rect.get_x() + rect.get_width()/2.0,\n",
        "                 top_point + 2,\n",
        "                 f'{mean_val:.1f}%',\n",
        "                 ha='center', va='bottom', fontsize=11, fontweight='bold', color='black')\n",
        "\n",
        "        if top_point > max_y_limit:\n",
        "            max_y_limit = top_point\n",
        "\n",
        "    plt.ylabel(\"Refusal Rate (%)\", fontsize=12, fontweight='bold')\n",
        "    plt.title(f\"{model_name} Training Refusal Rates\", fontsize=14)\n",
        "    plt.xticks(x_pos, methods, fontsize=10)\n",
        "\n",
        "    plt.ylim(0, max_y_limit * 1.15)\n",
        "\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "    plt.gca().set_axisbelow(True)\n",
        "\n",
        "\n",
        "    patches = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in methods]\n",
        "    plt.legend(patches, methods, loc='upper center', bbox_to_anchor=(0.5, 1.15), ncol=3, frameon=False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if not outputs_dir.exists():\n",
        "        print(f\"NOTE: Directory {outputs_dir} not found.\")\n",
        "        print(\"Please edit the 'outputs_dir' variable at the top of the script.\")\n",
        "    else:\n",
        "        df = load_refusal_data(outputs_dir)\n",
        "\n",
        "        if not df.empty:\n",
        "            stats_df = aggregate_stats(df)\n",
        "            print(\"\\nAggregated Stats Table:\")\n",
        "            print(stats_df[['Method', 'mean', 'min', 'max']].to_string(index=False))\n",
        "            plot_figure_3_style(stats_df)\n",
        "        else:\n",
        "            print(\"No data found to plot. Check your folder structure.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
